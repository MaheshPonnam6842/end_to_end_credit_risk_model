# ğŸš€ End-to-End Credit Risk Prediction System (Production-Grade)

This repository contains a **production-ready, end-to-end Machine Learning system** for **credit risk prediction**, built using **industry-standard ML engineering, MLOps, and DevOps practices**.

The project goes beyond model building and focuses on **automation, deployment, and real-world production readiness**, similar to how ML systems are built and deployed in financial services and fintech organizations.

---

## ğŸ§  Problem Statement

Credit risk assessment is a critical function in banking and financial services.  
The objective of this project is to **predict the probability of loan default** using customer, loan, and repayment behavior data, and expose the model through a **production inference service**.

Instead of stopping at notebooks, this project demonstrates **full ownership of the ML lifecycle** â€” from data ingestion to automated cloud deployment.

---

## ğŸ—ï¸ High-Level Architecture

Data Sources
â†“
Feature Engineering & Selection
â†“
Preprocessing Pipeline
â†“
Model Training & Evaluation
â†“
Model + Preprocessor Artifacts
â†“
Dockerized Flask Inference Service
â†“
CI/CD via GitHub Actions
â†“
Amazon ECR (Private Registry)
â†“
EC2 Production Deployment

markdown
Copy code

---
flowchart LR
    User[User / Browser] -->|HTTP Request| FlaskApp[Flask Web App]

    FlaskApp --> PredictPipeline[Prediction Pipeline]

    PredictPipeline --> Preprocessor[Preprocessor.pkl]
    PredictPipeline --> Model[Trained ML Model.pkl]

    Preprocessor --> FeatureEngineering[Feature Engineering + Encoding + Scaling]
    FeatureEngineering --> Model

    Model -->|Probability Output| FlaskApp
    FlaskApp -->|Risk Score + Label| User

    subgraph Training Pipeline
        Data[Raw Data] --> Ingestion[Data Ingestion]
        Ingestion --> Transformation[Data Transformation]
        Transformation --> SMOTE[SMOTE Balancing]
        SMOTE --> Training[Model Training (XGBoost)]
        Training --> Model
        Transformation --> Preprocessor
    end

    subgraph CI/CD
        GitHub[GitHub Repo] --> Actions[GitHub Actions]
        Actions --> ECR[AWS ECR]
        ECR --> EC2[AWS EC2]
    end

    EC2 --> FlaskApp

## ğŸ”‘ Key Highlights

- End-to-end ML lifecycle (ingestion â†’ training â†’ inference)
- Feature engineering aligned between training and inference
- Class imbalance handled using **SMOTE**
- Multiple models evaluated (Logistic Regression, Random Forest, XGBoost)
- Best model selected using **ROC-AUC**
- Probability-based predictions (not just 0/1 output)
- Fully Dockerized application
- **CI/CD pipeline** using GitHub Actions
- **Private container registry (Amazon ECR)**
- **Automated deployment to EC2 using a self-hosted runner**

---
## ğŸ“ System Architecture

This diagram shows the end-to-end architecture of the Credit Risk Prediction system, 
covering training, inference, Dockerization, and AWS deployment.

![Project Architecture](assets/Project_Architecture.png)

## ğŸ“Š Model Performance

Below is the comparison of model performance (AUC-ROC) across different algorithms 
used during experimentation.

![Best Model Scores](assets/Best_model_scores.png)


## ğŸ“Š Machine Learning Details

### Feature Engineering
Domain-driven features such as:
- Loan-to-Income Ratio
- Delinquency Ratio
- Average DPD per Delinquency
- Credit Utilization Metrics

### Feature Selection
Final features selected using:
- Domain knowledge
- Exploratory Data Analysis (EDA)
- Correlation analysis
- Feature importance
- Multicollinearity checks (VIF)

### Models Trained
- Logistic Regression (baseline, interpretable)
- Random Forest
- **XGBoost (final production model)**

### Evaluation Metrics
- ROC-AUC (primary metric)
- Precision, Recall, F1-score
- SMOTE applied to handle class imbalance

---

## ğŸ§ª Training Pipeline

- Modular pipeline structure
- Saved artifacts:
  - `model.pkl`
  - `preprocessor.pkl`
- Strict consistency between training and inference pipelines
- Reproducible training workflow

---

## ğŸŒ Inference Application

- Flask-based web application
- User-friendly form input
- Outputs:
  - Risk classification (High / Low)
  - Probability of default (percentage)
- Clean separation between:
  - API logic
  - Prediction logic
  - Feature processing

---

## ğŸ³ Dockerization

- Application fully containerized using Docker
- Same image used across:
  - Local testing
  - CI/CD pipeline
  - Production deployment
- No dependency on local environment

---

## ğŸ”„ CI/CD Pipeline (GitHub Actions)

On every push to the `main` branch:

1. **Continuous Integration**
   - Code checkout
   - Lint / test stage (extendable)

2. **Continuous Delivery**
   - Docker image build
   - Image pushed to **Amazon ECR**

3. **Continuous Deployment**
   - Self-hosted GitHub runner on EC2
   - Pulls latest image from ECR
   - Stops old container
   - Runs new container automatically

**Deployment is fully automated with zero manual intervention.**

---

## â˜ï¸ Cloud & Infrastructure

- **Amazon EC2** â€“ Compute
- **Amazon ECR** â€“ Private container registry
- **IAM User** â€“ Secure access (upgradeable to IAM Role)
- **Security Groups** â€“ Controlled ingress (SSH + App port)

---

## ğŸ› ï¸ Tech Stack

### Machine Learning
- Python
- Pandas, NumPy
- Scikit-learn
- XGBoost
- Imbalanced-learn (SMOTE)

### Backend & Deployment
- Flask
- Docker
- GitHub Actions
- Amazon EC2
- Amazon ECR
- Linux (Ubuntu / Amazon Linux)

---

## ğŸ“ Project Structure

## ğŸ“ Project Structure

```text
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”‚   â””â”€â”€ predict_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ exception.py
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ preprocessor.pkl
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ home.html
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml
â”‚
â””â”€â”€ README.md
```

### Structure Overview
- `src/components` â€“ Core ML components (ingestion, transformation, training)
- `src/pipeline` â€“ Training and inference pipelines
- `artifacts` â€“ Serialized model and preprocessing objects
- `templates` â€“ Flask UI templates
- `Dockerfile` â€“ Containerization configuration
- `.github/workflows` â€“ CI/CD pipeline using GitHub Actions



yaml
Copy code

---

## ğŸš€ Run Locally Using Docker

```bash
docker build -t credit-risk-app .
docker run -p 5000:5000 credit-risk-app
Access the application at:

arduino
Copy code
http://localhost:5000
ğŸ“Œ Production Deployment
Docker image stored in Amazon ECR

Automatically deployed on EC2

Triggered via GitHub Actions on every push to main

ğŸ”® Future Enhancements
SHAP-based explainability for single predictions

Gunicorn + Nginx for high-throughput serving

ECS / Auto-scaling deployment

Monitoring with CloudWatch

Model versioning and rollback strategy

ğŸ‘¤ Author
Mahesh Ponnam
Data Scientist | Machine Learning | MLOps

Focused on building production-ready ML systems, not just notebooks.
